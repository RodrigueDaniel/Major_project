{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6423445a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the stacking model...\n",
      "Training complete.\n",
      "\n",
      "===== Model Performance =====\n",
      "RMSE: 1.7813\n",
      "R²:   0.9991\n",
      "MAE:  1.1917\n",
      "\n",
      "===== Meta-Learner Parameters =====\n",
      "Optimal Lambda (λ): 0.0001\n",
      "\n",
      "Intercept (β₀): -16.1825\n",
      "Weight for ElasticNet (β₁): 0.0226\n",
      "Weight for SVR (β₂): \t-0.2015\n",
      "Weight for KNN (β₃): \t0.3881\n",
      "Weight for GBR (β₄): \t0.8295\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import ElasticNet, RidgeCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, StackingRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.datasets import make_regression # Added for creating a sample dataset\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "# I am creating a sample dataset here so the script can run.\n",
    "# REPLACE THIS PART with your own data loading code.\n",
    "df = pd.read_csv(r\"D:\\Coding\\Major-Project\\new_\\data\\preprocessed_data.csv\")\n",
    "#X, y = make_regression(n_samples=1500, n_features=8, noise=25, random_state=42)\n",
    "# You would then define your X and y from your dataframe 'df'\n",
    "X = df[[\"I\",\"P\",\"Q\",\"T\",\"Hydrogen\",\"Oxygen\",\"RH anode\",\"Rh Cathode\"]].values\n",
    "y = df[\"V\"].values\n",
    "\n",
    "# --- 2. Split Data ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- 3. Define the Stacking Model ---\n",
    "# Define the base models (Layer 0)\n",
    "# A more competitive set of base learners with tweaked hyperparameters\n",
    "# A more competitive set of base learners with tweaked hyperparameters\n",
    "# base_learners = [\n",
    "#     (\"enet\", make_pipeline(StandardScaler(), ElasticNet(alpha=0.01, l1_ratio=0.9, max_iter=5000))),\n",
    "#     (\"svr\",  make_pipeline(StandardScaler(), SVR(kernel=\"rbf\", C=100, gamma='auto', epsilon=0.1))),\n",
    "#     (\"knn\",  make_pipeline(StandardScaler(), KNeighborsRegressor(n_neighbors=5, weights='distance'))),\n",
    "#     (\"gbr\",  GradientBoostingRegressor(n_estimators=150, learning_rate=0.1, max_depth=4, random_state=42))\n",
    "# ]\n",
    "\n",
    "# A more competitive set of base learners with a heavily simplified GBR\n",
    "# base_learners = [\n",
    "#     (\"enet\", make_pipeline(StandardScaler(), ElasticNet(alpha=0.01, l1_ratio=0.9, max_iter=5000))),\n",
    "#     (\"svr\",  make_pipeline(StandardScaler(), SVR(kernel=\"rbf\", C=100, gamma='auto', epsilon=0.1))),\n",
    "#     (\"knn\",  make_pipeline(StandardScaler(), KNeighborsRegressor(n_neighbors=5, weights='distance'))),\n",
    "#     # Drastic simplification of GBR to force other models to contribute more\n",
    "#     (\"gbr\",  GradientBoostingRegressor(n_estimators=50, learning_rate=0.1, max_depth=2, random_state=42))\n",
    "# ]\n",
    "base_learners = [\n",
    "    (\"enet\", make_pipeline(StandardScaler(), ElasticNet(alpha=0.01, l1_ratio=0.9, max_iter=5000))),\n",
    "    (\"svr\",  make_pipeline(StandardScaler(), SVR(kernel=\"rbf\", C=100, gamma='auto', epsilon=0.1))),\n",
    "    (\"knn\",  make_pipeline(StandardScaler(), KNeighborsRegressor(n_neighbors=5, weights='distance'))),\n",
    "    # Drastic simplification of GBR to force other models to contribute more\n",
    "    (\"gbr\",  GradientBoostingRegressor(n_estimators=30, learning_rate=0.1, max_depth=2, random_state=42))\n",
    "]\n",
    "\n",
    "# Define the meta-model (Layer 1)\n",
    "meta_learner = RidgeCV(alphas=np.logspace(-4, 4, 25))\n",
    "\n",
    "# Create the full stacking regressor\n",
    "stacking_model = StackingRegressor(\n",
    "    estimators=base_learners,\n",
    "    final_estimator=meta_learner,\n",
    "    cv=5,\n",
    "    passthrough=False\n",
    ")\n",
    "\n",
    "# --- 4. Train the Model ---\n",
    "print(\"Training the stacking model...\")\n",
    "stacking_model.fit(X_train, y_train)\n",
    "print(\"Training complete.\")\n",
    "\n",
    "# --- 5. Evaluate the Model ---\n",
    "y_pred = stacking_model.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"\\n===== Model Performance =====\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R²:   {r2:.4f}\")\n",
    "print(f\"MAE:  {mae:.4f}\")\n",
    "\n",
    "# --- 6. EXTRACT AND PRINT THE META-LEARNER PARAMETERS ---\n",
    "# This is the section that extracts the values you asked for.\n",
    "\n",
    "# Get the optimal Lambda (λ) found by RidgeCV\n",
    "lambda_val = stacking_model.final_estimator_.alpha_\n",
    "\n",
    "# Get the Intercept (β₀)\n",
    "beta_0 = stacking_model.final_estimator_.intercept_\n",
    "\n",
    "# Get the weights for each base learner (β₁ to β₄)\n",
    "beta_coeffs = stacking_model.final_estimator_.coef_\n",
    "\n",
    "# Print the results in a clear format\n",
    "print(\"\\n===== Meta-Learner Parameters =====\")\n",
    "print(f\"Optimal Lambda (λ): {lambda_val:.4f}\\n\")\n",
    "print(f\"Intercept (β₀): {beta_0:.4f}\")\n",
    "# The order of the coefficients matches the order in the 'base_learners' list\n",
    "print(f\"Weight for ElasticNet (β₁): {beta_coeffs[0]:.4f}\")\n",
    "print(f\"Weight for SVR (β₂): \\t{beta_coeffs[1]:.4f}\")\n",
    "print(f\"Weight for KNN (β₃): \\t{beta_coeffs[2]:.4f}\")\n",
    "print(f\"Weight for GBR (β₄): \\t{beta_coeffs[3]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06642281",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
